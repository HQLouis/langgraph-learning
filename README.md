# Lingolino Learning - Backend API

## ğŸ¯ Project Overview

This repository contains the Lingolino agentic learning system with a FastAPI backend for managing conversational interactions.

## ğŸ“ Project Structure

```
langgraph-learning/
â”œâ”€â”€ agentic-system/          # Core agentic system logic
â”‚   â”œâ”€â”€ background_graph.py  # Background analysis workers
â”‚   â”œâ”€â”€ immediate_graph.py   # Real-time response graph
â”‚   â”œâ”€â”€ nodes.py            # Graph nodes
â”‚   â”œâ”€â”€ states.py           # State definitions
â”‚   â””â”€â”€ chat.py             # CLI interface
â”œâ”€â”€ backend/                 # FastAPI application
â”‚   â”œâ”€â”€ api/                # API routes and dependencies
â”‚   â”œâ”€â”€ services/           # Business logic layer
â”‚   â”œâ”€â”€ models/             # Pydantic schemas
â”‚   â”œâ”€â”€ core/               # Configuration
â”‚   â””â”€â”€ main.py             # Application entry point
â”œâ”€â”€ examples/               # Example clients
â”‚   â”œâ”€â”€ test_api_client.py  # Python client example
â”‚   â”œâ”€â”€ curl_examples.py    # curl commands
â”‚   â””â”€â”€ web_client_example.html  # Browser-based demo
â”œâ”€â”€ functional-testing/     # Functional tests
â”œâ”€â”€ langgraph_tutorial/     # LangGraph tutorials
â””â”€â”€ frontend/              # (Future) Frontend application
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
uv sync
```

### 2. Configure Environment

Create a `.env` file in the root directory with your Google API credentials:

```env
GOOGLE_API_KEY=your_api_key_here
```

### 3. Start the API Server

```bash
./start_api.sh
```

Or manually:

```bash
python -m backend.main
```

The API will be available at:
- **API**: http://localhost:8000
- **Interactive Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### 4. Test the API

#### Using the Web Client (Easiest)

Open `examples/web_client_example.html` in your browser and start chatting!

#### Using Python Client

```bash
# Install additional dependency
uv pip install sseclient-py

# Run the test client
python examples/test_api_client.py
```

#### Using curl

```bash
# Health check
curl http://localhost:8000/health

# Create conversation
curl -X POST http://localhost:8000/conversations \
  -H "Content-Type: application/json" \
  -d '{"child_id": "1", "game_id": "0"}'

# Send message (replace THREAD_ID)
curl -X POST http://localhost:8000/conversations/THREAD_ID/messages \
  -H "Content-Type: application/json" \
  -H "Accept: text/event-stream" \
  -d '{"message": "Hello!"}' \
  --no-buffer
```

## ğŸ“š API Documentation

See [backend/README.md](backend/README.md) for comprehensive API documentation.

### Key Endpoints

- `POST /conversations` - Create new conversation
- `POST /conversations/{thread_id}/messages` - Send message (SSE streaming)
- `GET /conversations/{thread_id}` - Get conversation history
- `DELETE /conversations/{thread_id}` - Delete conversation
- `GET /health` - Health check

## ğŸ”§ Features

- âœ… RESTful API with FastAPI
- âœ… Server-Sent Events (SSE) for real-time streaming
- âœ… Rate limiting (60 req/min)
- âœ… CORS support for frontend integration
- âœ… Comprehensive error handling
- âœ… Auto-generated API documentation
- âœ… Session management
- âœ… Background analysis processing

## ğŸ§ª Development

### Running Tests

```bash
# Functional tests
python -m pytest functional-testing/
```

### CLI Chat Interface

For testing the agentic system without the API:

```bash
python agentic-system/chat.py
```

## ğŸ—ï¸ Architecture

### Backend Architecture

- **API Layer** (`backend/api/`): FastAPI routes and dependencies
- **Service Layer** (`backend/services/`): Business logic and orchestration
- **Models** (`backend/models/`): Pydantic schemas for validation
- **Core** (`backend/core/`): Configuration and utilities

### Agentic System

- **Immediate Graph**: Real-time responses to user messages
- **Background Graph**: Asynchronous analysis (educational & storytelling)
- **State Management**: LangGraph MemorySaver (in-memory)

### Streaming Strategy

Uses **Server-Sent Events (SSE)** for unidirectional streaming:
- Simpler than WebSockets
- HTTP-based, better proxy/firewall support
- Automatic reconnection
- Perfect for chat streaming use case

## ğŸ” Security & Production

### Authentication (Ready to Add)

The architecture supports easy authentication integration:

```python
# Add to backend/api/dependencies.py
async def get_current_user(token: str = Depends(security)):
    # Your auth logic here
    return user

# Add to routes
@router.post("/conversations", dependencies=[Depends(get_current_user)])
```

### Rate Limiting

Configured via environment variables:
- Default: 60 requests/minute per IP
- Configurable in `backend/core/config.py`

### CORS

Configure allowed origins for production in `.env`:

```env
CORS_ORIGINS=["https://your-frontend.com"]
```

## ğŸ“¦ Dependencies

Main dependencies:
- **FastAPI**: Web framework
- **Uvicorn**: ASGI server
- **LangChain**: LLM framework
- **LangGraph**: Graph-based workflows
- **Pydantic**: Data validation
- **SlowAPI**: Rate limiting

## ğŸ›£ï¸ Roadmap

- [ ] Add persistent storage (PostgreSQL)
- [ ] Implement authentication
- [ ] Add Redis for caching
- [ ] WebSocket support (if needed)
- [ ] Frontend application
- [ ] Docker containerization
- [ ] Kubernetes deployment configs
- [ ] Monitoring & logging (Prometheus, Grafana)

## ğŸ“ License

See LICENSE file for details.

## ğŸ¤ Contributing

This is a learning project. Contributions welcome!

---

**Made with â¤ï¸ using FastAPI, LangChain, and LangGraph**

